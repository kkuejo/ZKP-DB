"""
æº–åŒå‹æš—å·ã‚’ä½¿ã£ãŸæ©Ÿæ¢°å­¦ç¿’ã®å®Ÿè£…

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã¯ã€æš—å·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ä»¥ä¸‹ã®MLã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š
1. ç·šå½¢å›å¸°
2. ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆå¤šé …å¼è¿‘ä¼¼ï¼‰
3. æµ…ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
"""

import json
import numpy as np
import tenseal as ts
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score, r2_score
import pickle


class EncryptedLinearRegression:
    """
    æº–åŒå‹æš—å·åŒ–ã•ã‚ŒãŸç·šå½¢å›å¸°

    æš—å·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã¾ã™
    """

    def __init__(self, context):
        """
        Args:
            context: TenSEALã®æš—å·åŒ–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        self.context = context
        self.weights = None
        self.bias = None
        self.scaler = StandardScaler()

    def train(self, X, y):
        """
        å¹³æ–‡ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ï¼ˆé€šå¸¸ã®æ©Ÿæ¢°å­¦ç¿’ï¼‰

        Args:
            X: ç‰¹å¾´é‡ (n_samples, n_features)
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (n_samples,)
        """
        print("ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")

        # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
        X_scaled = self.scaler.fit_transform(X)

        # ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        model = LinearRegression()
        model.fit(X_scaled, y)

        self.weights = model.coef_
        self.bias = model.intercept_

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½è©•ä¾¡
        y_pred = model.predict(X_scaled)
        mse = mean_squared_error(y, y_pred)
        r2 = r2_score(y, y_pred)

        print(f"  è¨“ç·´å®Œäº†")
        print(f"  MSE: {mse:.2f}")
        print(f"  RÂ²: {r2:.3f}")
        print(f"  é‡ã¿: {self.weights}")
        print(f"  ãƒã‚¤ã‚¢ã‚¹: {self.bias:.2f}")

        return self

    def predict_encrypted(self, X_encrypted):
        """
        æš—å·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬

        Args:
            X_encrypted: æš—å·åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ

        Returns:
            æš—å·åŒ–ã•ã‚ŒãŸäºˆæ¸¬å€¤
        """
        if self.weights is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾ç·šå½¢æ¼”ç®—: y = w1*x1 + w2*x2 + ... + b
        prediction = X_encrypted[0] * float(self.weights[0])

        for i in range(1, len(self.weights)):
            prediction = prediction + (X_encrypted[i] * float(self.weights[i]))

        # ãƒã‚¤ã‚¢ã‚¹é …ã‚’åŠ ç®—
        prediction = prediction + float(self.bias)

        return prediction

    def decrypt_prediction(self, encrypted_pred):
        """
        äºˆæ¸¬å€¤ã‚’å¾©å·
        """
        return encrypted_pred.decrypt()[0]


class EncryptedLogisticRegression:
    """
    æº–åŒå‹æš—å·åŒ–ã•ã‚ŒãŸãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°

    Sigmoidé–¢æ•°ã‚’å¤šé …å¼ã§è¿‘ä¼¼ã—ã¦å®Ÿè£…
    """

    def __init__(self, context):
        self.context = context
        self.weights = None
        self.bias = None
        self.scaler = StandardScaler()

    def sigmoid_poly_approx(self, x):
        """
        Sigmoidé–¢æ•°ã®å¤šé …å¼è¿‘ä¼¼

        Ïƒ(x) â‰ˆ 0.5 + 0.197x - 0.004xÂ³
        (ç¯„å›²: -5 <= x <= 5 ã§ç²¾åº¦ãŒé«˜ã„)

        Args:
            x: æš—å·åŒ–ã•ã‚ŒãŸå€¤

        Returns:
            æš—å·åŒ–ã•ã‚ŒãŸSigmoidè¿‘ä¼¼å€¤
        """
        # 0.5 + 0.197x - 0.004xÂ³
        x_cubed = x * x * x
        result = x * 0.197 + x_cubed * (-0.004) + 0.5
        return result

    def train(self, X, y):
        """
        ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’è¨“ç·´

        Args:
            X: ç‰¹å¾´é‡
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆ0 or 1ï¼‰
        """
        print("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")

        # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
        X_scaled = self.scaler.fit_transform(X)

        # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’è¨“ç·´
        model = LogisticRegression(max_iter=1000)
        model.fit(X_scaled, y)

        self.weights = model.coef_[0]
        self.bias = model.intercept_[0]

        # æ€§èƒ½è©•ä¾¡
        y_pred = model.predict(X_scaled)
        accuracy = accuracy_score(y, y_pred)

        print(f"  è¨“ç·´å®Œäº†")
        print(f"  ç²¾åº¦: {accuracy:.3f}")
        print(f"  é‡ã¿: {self.weights}")
        print(f"  ãƒã‚¤ã‚¢ã‚¹: {self.bias:.2f}")

        return self

    def predict_encrypted(self, X_encrypted):
        """
        æš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰

        Args:
            X_encrypted: æš—å·åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ

        Returns:
            æš—å·åŒ–ã•ã‚ŒãŸäºˆæ¸¬ç¢ºç‡
        """
        if self.weights is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # ç·šå½¢éƒ¨åˆ†: z = wÂ·x + b
        z = X_encrypted[0] * float(self.weights[0])
        for i in range(1, len(self.weights)):
            z = z + (X_encrypted[i] * float(self.weights[i]))
        z = z + float(self.bias)

        # Sigmoidè¿‘ä¼¼
        prob = self.sigmoid_poly_approx(z)

        return prob


class EncryptedNeuralNetwork:
    """
    æš—å·åŒ–ã•ã‚ŒãŸæµ…ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

    æ§‹é€ : å…¥åŠ›å±¤ â†’ éš ã‚Œå±¤(4ãƒãƒ¼ãƒ‰) â†’ å‡ºåŠ›å±¤
    æ´»æ€§åŒ–é–¢æ•°: å¤šé …å¼è¿‘ä¼¼
    """

    def __init__(self, context, input_dim=4, hidden_dim=4):
        self.context = context
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim

        # é‡ã¿ï¼ˆè¨“ç·´å¾Œã«è¨­å®šï¼‰
        self.W1 = None  # (input_dim, hidden_dim)
        self.b1 = None  # (hidden_dim,)
        self.W2 = None  # (hidden_dim, 1)
        self.b2 = None  # (1,)

        self.scaler = StandardScaler()

    def activation_poly(self, x):
        """
        ReLUé¢¨ã®å¤šé …å¼è¿‘ä¼¼æ´»æ€§åŒ–é–¢æ•°

        f(x) â‰ˆ x + 0.5xÂ² - 0.05xÂ³
        """
        x_squared = x * x
        x_cubed = x_squared * x
        result = x + x_squared * 0.5 + x_cubed * (-0.05)
        return result

    def train_simple(self, X, y):
        """
        ç°¡å˜ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´

        å®Ÿéš›ã«ã¯ã€äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸé‡ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
        å®Œå…¨ãªæº–åŒå‹æš—å·åŒ–ã§ã®è¨“ç·´ã¯éå¸¸ã«è¤‡é›‘ã§ã™ã€‚
        """
        print("ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´ä¸­...")

        X_scaled = self.scaler.fit_transform(X)

        # ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿ã§åˆæœŸåŒ–ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šè‰¯ã„è¨“ç·´æ–¹æ³•ã‚’ä½¿ç”¨ï¼‰
        np.random.seed(42)
        self.W1 = np.random.randn(self.input_dim, self.hidden_dim) * 0.1
        self.b1 = np.zeros(self.hidden_dim)
        self.W2 = np.random.randn(self.hidden_dim, 1) * 0.1
        self.b2 = np.zeros(1)

        print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ : {self.input_dim} â†’ {self.hidden_dim} â†’ 1")
        print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {self.W1.size + self.b1.size + self.W2.size + self.b2.size}")

        return self

    def forward_encrypted(self, X_encrypted):
        """
        æš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã§é †ä¼æ’­

        Args:
            X_encrypted: æš—å·åŒ–ã•ã‚ŒãŸå…¥åŠ›ã®ãƒªã‚¹ãƒˆ [enc(x1), enc(x2), ...]

        Returns:
            æš—å·åŒ–ã•ã‚ŒãŸå‡ºåŠ›
        """
        if self.W1 is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # éš ã‚Œå±¤ã®è¨ˆç®—
        hidden = []
        for j in range(self.hidden_dim):
            # h_j = activation(sum(W1[i,j] * x[i]) + b1[j])
            h = X_encrypted[0] * float(self.W1[0, j])
            for i in range(1, self.input_dim):
                h = h + (X_encrypted[i] * float(self.W1[i, j]))
            h = h + float(self.b1[j])

            # æ´»æ€§åŒ–é–¢æ•°
            h = self.activation_poly(h)
            hidden.append(h)

        # å‡ºåŠ›å±¤ã®è¨ˆç®—
        output = hidden[0] * float(self.W2[0, 0])
        for j in range(1, self.hidden_dim):
            output = output + (hidden[j] * float(self.W2[j, 0]))
        output = output + float(self.b2[0])

        return output


def demonstrate_ml_tasks():
    """
    æ§˜ã€…ãªæ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¢
    """
    print("="*70)
    print("æº–åŒå‹æš—å·ã‚’ä½¿ã£ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ‡ãƒ¢")
    print("="*70)

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print("\næ‚£è€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    with open('data/patients.json', 'r', encoding='utf-8') as f:
        patients = json.load(f)

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æº–å‚™
    X = np.array([
        [p['age'], p['blood_pressure_systolic'],
         p['blood_sugar'], p['cholesterol']]
        for p in patients
    ])

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ1: BMIï¼ˆå›å¸°ã‚¿ã‚¹ã‚¯ï¼‰
    y_regression = np.array([p['bmi'] for p in patients])

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ2: é«˜è¡€åœ§ã®æœ‰ç„¡ï¼ˆåˆ†é¡ã‚¿ã‚¹ã‚¯ï¼‰
    y_classification = np.array([
        1 if p['blood_pressure_systolic'] >= 140 else 0
        for p in patients
    ])

    print(f"âœ“ {len(patients)}äººã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    print(f"  ç‰¹å¾´é‡: å¹´é½¢ã€åç¸®æœŸè¡€åœ§ã€è¡€ç³–å€¤ã€ã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«")

    # æš—å·åŒ–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
    context = ts.context(
        ts.SCHEME_TYPE.CKKS,
        poly_modulus_degree=8192,
        coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.generate_galois_keys()
    context.generate_relin_keys()
    context.global_scale = 2**40

    # ========================================
    # ã‚¿ã‚¹ã‚¯1: ç·šå½¢å›å¸°
    # ========================================
    print("\n" + "="*70)
    print("ã‚¿ã‚¹ã‚¯1: ç·šå½¢å›å¸°ã§BMIã‚’äºˆæ¸¬")
    print("="*70)

    lr_model = EncryptedLinearRegression(context)
    lr_model.train(X, y_regression)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ï¼ˆæš—å·åŒ–ï¼‰
    print("\næš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")
    test_idx = 0
    test_patient = patients[test_idx]

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æš—å·åŒ–
    X_test_encrypted = [
        ts.ckks_vector(context, [float(test_patient['age'])]),
        ts.ckks_vector(context, [float(test_patient['blood_pressure_systolic'])]),
        ts.ckks_vector(context, [float(test_patient['blood_sugar'])]),
        ts.ckks_vector(context, [float(test_patient['cholesterol'])])
    ]

    # æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾äºˆæ¸¬
    encrypted_pred = lr_model.predict_encrypted(X_test_encrypted)
    predicted_bmi = lr_model.decrypt_prediction(encrypted_pred)
    actual_bmi = test_patient['bmi']

    print(f"\næ‚£è€… {test_patient['patient_id']} ã®äºˆæ¸¬çµæœ:")
    print(f"  å®Ÿéš›ã®BMI: {actual_bmi:.1f}")
    print(f"  äºˆæ¸¬BMI: {predicted_bmi:.1f}")
    print(f"  èª¤å·®: {abs(predicted_bmi - actual_bmi):.2f}")
    print("\nâœ… ãƒ‡ãƒ¼ã‚¿ã¯æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾äºˆæ¸¬ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸï¼")

    # ========================================
    # ã‚¿ã‚¹ã‚¯2: ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°
    # ========================================
    print("\n" + "="*70)
    print("ã‚¿ã‚¹ã‚¯2: ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã§é«˜è¡€åœ§ã‚’äºˆæ¸¬")
    print("="*70)

    logistic_model = EncryptedLogisticRegression(context)
    logistic_model.train(X, y_classification)

    print("\næš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")

    # æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰
    encrypted_prob = logistic_model.predict_encrypted(X_test_encrypted)
    predicted_prob = encrypted_prob.decrypt()[0]
    actual_label = y_classification[test_idx]

    print(f"\næ‚£è€… {test_patient['patient_id']} ã®äºˆæ¸¬çµæœ:")
    print(f"  å®Ÿéš›ã®è¡€åœ§: {test_patient['blood_pressure_systolic']} mmHg")
    print(f"  é«˜è¡€åœ§ãƒ©ãƒ™ãƒ«: {'é«˜è¡€åœ§' if actual_label == 1 else 'æ­£å¸¸'}")
    print(f"  äºˆæ¸¬ç¢ºç‡: {predicted_prob:.3f}")
    print(f"  äºˆæ¸¬ãƒ©ãƒ™ãƒ«: {'é«˜è¡€åœ§' if predicted_prob > 0.5 else 'æ­£å¸¸'}")
    print("\nâœ… Sigmoidé–¢æ•°ã‚’å¤šé …å¼è¿‘ä¼¼ã—ã¦æš—å·åŒ–ã®ã¾ã¾è¨ˆç®—ã—ã¾ã—ãŸï¼")

    # ========================================
    # ã‚¿ã‚¹ã‚¯3: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    # ========================================
    print("\n" + "="*70)
    print("ã‚¿ã‚¹ã‚¯3: æµ…ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
    print("="*70)

    nn_model = EncryptedNeuralNetwork(context, input_dim=4, hidden_dim=4)
    nn_model.train_simple(X, y_regression)

    print("\næš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")

    # æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾é †ä¼æ’­
    encrypted_output = nn_model.forward_encrypted(X_test_encrypted)
    nn_prediction = encrypted_output.decrypt()[0]

    print(f"\næ‚£è€… {test_patient['patient_id']} ã®äºˆæ¸¬çµæœ:")
    print(f"  ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›: {nn_prediction:.2f}")
    print("\nâœ… å¤šå±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æš—å·åŒ–ã®ã¾ã¾å®Ÿè¡Œã—ã¾ã—ãŸï¼")

    # ========================================
    # ã¾ã¨ã‚
    # ========================================
    print("\n" + "="*70)
    print("æº–åŒå‹æš—å·ã§ã®ML: ä½•ãŒã§ãã‚‹ã‹")
    print("="*70)
    print("""
âœ… å®Ÿè£…å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:
  1. ç·šå½¢å›å¸° - å®Œå…¨ã«å¯èƒ½
  2. ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° - å¤šé …å¼è¿‘ä¼¼ã§å¯èƒ½
  3. æµ…ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ - 2-3å±¤ãªã‚‰å¯èƒ½
  4. æ±ºå®šæœ¨ - ä¸€éƒ¨ã®æ“ä½œã¯å¯èƒ½
  5. k-means - ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢è¨ˆç®—ãŒå¯èƒ½

âš ï¸  åˆ¶é™äº‹é …:
  1. æ·±ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ - ä¹—ç®—ã®æ·±ã•åˆ¶é™
  2. ReLU, Sigmoid - å¤šé …å¼è¿‘ä¼¼ãŒå¿…è¦ï¼ˆç²¾åº¦ä½ä¸‹ï¼‰
  3. æ¯”è¼ƒæ¼”ç®— - ifæ–‡ã€max/minãŒå›°é›£
  4. å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ« - è¨ˆç®—æ™‚é–“ãŒé•·ã„

ğŸ’¡ å®Ÿç”¨çš„ãªè§£æ±ºç­–:
  1. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼: ä¸€éƒ¨ã‚’æš—å·åŒ–ã€ä¸€éƒ¨ã‚’å¹³æ–‡
  2. è»¢ç§»å­¦ç¿’: æš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
  3. çŸ¥è­˜è’¸ç•™: å¤§ããªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å°ã•ãªãƒ¢ãƒ‡ãƒ«ã¸
  4. Federated Learning: ãƒ‡ãƒ¼ã‚¿ã¯å„æ‰€ã«æ®‹ã—ãŸã¾ã¾å­¦ç¿’
    """)

    print("="*70)


def save_models():
    """
    è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    """
    print("\nè¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­...")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open('data/patients.json', 'r', encoding='utf-8') as f:
        patients = json.load(f)

    X = np.array([
        [p['age'], p['blood_pressure_systolic'],
         p['blood_sugar'], p['cholesterol']]
        for p in patients
    ])
    y_regression = np.array([p['bmi'] for p in patients])

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
    context = ts.context(
        ts.SCHEME_TYPE.CKKS,
        poly_modulus_degree=8192,
        coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.generate_galois_keys()
    context.generate_relin_keys()
    context.global_scale = 2**40

    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    lr_model = EncryptedLinearRegression(context)
    lr_model.train(X, y_regression)

    # ä¿å­˜
    with open('data/lr_model.pkl', 'wb') as f:
        pickle.dump({
            'weights': lr_model.weights,
            'bias': lr_model.bias,
            'scaler': lr_model.scaler
        }, f)

    print("âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ data/lr_model.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    demonstrate_ml_tasks()
    save_models()
